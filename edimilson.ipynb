{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bitd97582b59dad4cc1ae5048e63cf9d754",
   "display_name": "Python 3.8.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Código criado em 7 de Outubro de 2020\n",
    "#Por: github.com/ArthurHVS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Bloco de imports\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import json\n",
    "import pandas as pd \n",
    "from alpha_vantage.timeseries import TimeSeries \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Com qual ativo iremos treinar hoje?\n",
      "            1. open  2. high  ...  7. dividend amount  8. split coefficient\n",
      "date                          ...                                          \n",
      "2020-10-06    24.76    26.64  ...                 0.0                   1.0\n",
      "2020-10-05    24.60    24.90  ...                 0.0                   1.0\n",
      "2020-10-02    25.40    25.56  ...                 0.0                   1.0\n",
      "2020-10-01    25.32    26.08  ...                 0.0                   1.0\n",
      "2020-09-30    24.01    25.04  ...                 0.0                   1.0\n",
      "...             ...      ...  ...                 ...                   ...\n",
      "2017-04-18    22.82    24.79  ...                 0.0                   1.0\n",
      "2017-04-17    23.00    23.00  ...                 0.0                   1.0\n",
      "2017-04-13    22.97    23.01  ...                 0.0                   1.0\n",
      "2017-04-12    22.45    22.99  ...                 0.0                   1.0\n",
      "2017-04-11    21.81    22.98  ...                 0.0                   1.0\n",
      "\n",
      "[862 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "#Popula os vetores, os inverte e cria um dataset com os valores.\n",
    "close_array = []\n",
    "date_array = []\n",
    "\n",
    "print(\"Com qual ativo iremos treinar hoje?\")\n",
    "symb = input()\n",
    "chave = '18ETRMNXVZ4FU6SQ'\n",
    "ts = TimeSeries(key=chave,output_format='pandas', indexing_type='date')\n",
    "myFrame, metadata = ts.get_daily_adjusted(symbol=symb.lower() + '.sao', outputsize='full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = myFrame['4. close'][:400].values\n",
    "test_set = myFrame[400:].values\n",
    "    \n",
    "#Define o formato dos vetores de treino e teste, escalonando os para valores entre 0 e 1\n",
    "sc = MinMaxScaler()\n",
    "train_set = train_set.reshape(-1,1)\n",
    "test_set = test_set.reshape(-1,1)\n",
    "train_set_scaled = sc.fit_transform(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Popula os vetores x e y dos treinos, com os valores escalonados dos sets de treino e teste\n",
    "x_train = []\n",
    "y_train = []\n",
    "for i in range(60, 400):\n",
    "    x_train.append(train_set_scaled[i-60:i,0])\n",
    "    y_train.append(train_set_scaled[i,0])\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Layers da rede neural. 50 neurônios. Dropout 20% (impede overfitting).\n",
    "reg = Sequential()\n",
    "\n",
    "reg.add(LSTM(units = 50,return_sequences=True,input_shape=(x_train.shape[1],1)))\n",
    "reg.add(Dropout(0.2))\n",
    "\n",
    "reg.add(LSTM(units = 50,return_sequences=True))\n",
    "reg.add(Dropout(0.2))\n",
    "\n",
    "reg.add(LSTM(units = 50,return_sequences=True))\n",
    "reg.add(Dropout(0.2))\n",
    "\n",
    "reg.add(LSTM(units=50))\n",
    "reg.add(Dropout(0.2))\n",
    "\n",
    "#Layer output, compilação e fit do modelo. Por fim, salva o arquivo.\n",
    "reg.add(Dense(units=1))\n",
    "reg.compile(optimizer = 'adam',loss='mean_squared_error')\n",
    "reg.fit(x_train,y_train, epochs=20, batch_size =1,verbose=2)\n",
    "reg.save('savedModels/'+symb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = myFrame['Close'][len(myFrame)-len(test_set)-60:].values\n",
    "input = input.reshape(-1, 1)\n",
    "input = sc.transform(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = []\n",
    "for i in range(60, 400):\n",
    "    x_test.append(input[i-60:i, 0])\n",
    "x_test = np.array(x_test)\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = reg.predict(x_test)\n",
    "pred = sc.inverse_transform(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pred, color='green')\n",
    "plt.plot(test_set, color='red')\n",
    "plt.title('Será que foi?')\n",
    "plt.show()"
   ]
  }
 ]
}